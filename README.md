## PyTorch Transformer Implementation

This repository contains a PyTorch implementation of the Transformer model, based on the paper ["Attention is All You Need"](https://arxiv.org/abs/1706.03762) by Vaswani et al. (2017).

### Features

- Implements core Transformer components:
  - Encoder-decoder architecture
  - Multi-head attention
  - Positional encoding
  - Feed-forward network


